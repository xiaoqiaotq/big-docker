version: "3.2"

services:
  hadoop-master:
    image: xiaoqiaotq/hadoop:0.2
    hostname: hadoop-master
    ports:
      - { published: 50070, target: 50070, mode: host } # namenode ui
      - { published: 8088, target: 8088, mode: host }  # resourcemanager ui
      - { published: 50075, target: 50075, mode: host } #datanode ui
      - { published: 8042, target: 8042, mode: host }  #nodemanager ui
      - { published: 16010, target: 16010, mode: host }
      - { published: 10002, target: 10002, mode: host } #hiveserver2 ui
      - { published: 9083, target: 9083, mode: host } # hive meta store
      - { published: 19888, target: 19888, mode: host }
      - { published: 8080, target: 8080, mode: host } # spark master ui
      - { published: 8081, target: 8081, mode: host } # spark worker ui
      - { published: 4040, target: 4040, mode: host } # spark job detail
      - { published: 18080, target: 18080, mode: host } # spark history job
    deploy:
      placement:
        constraints: [node.role == manager]
    volumes:
      - hdfs:/root/hdfs/
#  hadoop-slave:
#    image: xiaoqiaotq/hadoop:0.1
#    ports:
#      - { published: 16030, target: 16030, mode: host }
  mysql:
    image: mysql:5.7
    environment:
      MYSQL_DATABASE: 'hive'
      # So you don't have to use root, but you can if you like
      MYSQL_USER: 'hive'
      # You can use whatever password you like
      MYSQL_PASSWORD: 'hive'
      # Password for root access
      MYSQL_ROOT_PASSWORD: 'admin'
    ports:
      # <Port exposed> : < MySQL Port running inside container>
      - '3306:3306'
    volumes:
      - mysql:/var/lib/mysql
volumes:
  mysql:
  hdfs: